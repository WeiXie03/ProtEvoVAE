{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from VAEmodel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enumd_msa.shape:  (320066, 79)\n",
      "seq_weights.shape:  (320066,)\n",
      "Number of sequences in loaded alignment:  320066\n",
      "Length of loaded alignment (final number of columns/a.a. positions in alignment for each sequence):  79\n",
      "Number of amino acid types: 21\n"
     ]
    }
   ],
   "source": [
    "# Load the processed MSA data\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../../data\")\n",
    "REF_SEQ_ID = \"PF00041\"\n",
    "AA_TYPES = ['R', 'H', 'K',\n",
    "      'D', 'E',\n",
    "      'S', 'T', 'N', 'Q',\n",
    "      'C', 'G', 'P',\n",
    "      'A', 'V', 'I', 'L', 'M', 'F', 'Y', 'W']\n",
    "\n",
    "enumd_msa = np.load(DATA_DIR / \"processed\" / \"enumd_mtx_{}.npy\".format(REF_SEQ_ID))\n",
    "print(\"enumd_msa.shape: \", enumd_msa.shape)\n",
    "seq_weights = np.load(DATA_DIR / \"processed\" / \"seq_weights_{}.npy\".format(REF_SEQ_ID))\n",
    "print(\"seq_weights.shape: \", seq_weights.shape)\n",
    "\n",
    "msa = MSA_Dataset(enumd_msa, seq_weights, np.array(AA_TYPES), MSA_to_OneHot)\n",
    "\n",
    "# check length = num of seqs\n",
    "print(\"Number of sequences in loaded alignment: \", len(msa))\n",
    "print(\"Length of loaded alignment (final number of columns/a.a. positions in alignment for each sequence): \", enumd_msa.shape[1])\n",
    "print(\"Number of amino acid types:\", len(AA_TYPES)+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available:  True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VAE(\n",
       "  (encoder_comm_layers): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Linear(in_features=1659, out_features=200, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): Linear(in_features=200, out_features=200, bias=True)\n",
       "      (1): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (enc_mu): Linear(in_features=200, out_features=2, bias=True)\n",
       "  (enc_logvars): Linear(in_features=200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import torch_xla.core.xla_model as xm\n",
    "# dev = xm.xla_device()\n",
    "\n",
    "print(\"GPU available: \", torch.cuda.is_available())\n",
    "dev = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2-dimensional latent space\n",
    "vae = VAE(len(AA_TYPES), 2, enumd_msa.shape[1] * (len(AA_TYPES)+1), [200, 200])\n",
    "vae.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "applying transform:  <VAEmodel.MSA_to_OneHot object at 0x7fe75ff0ffd0>\n",
      "before transform: [13 13  8 12  9 13 12  8  6  7 11  6  6 14  1 14 10 20  6 16 19  6 13 13\n",
      "  4  4  7 14  5  6 19  9 16  6 19  1 12 14  9  4 11  6  9  7  5 14  7 17\n",
      "  7 15  3  5 19 10  6 14  7  8 16 16 12  8  7  9 19  5 18 20 14  7 13  9\n",
      "  8  1 13 11 16  6 12]\n",
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "first_seq = msa[0][0].to(dev)\n",
    "print(first_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first layer should be  79  *  21  =  1659\n",
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Linear(in_features=1659, out_features=200, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (1): Tanh()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(\"first layer should be \", enumd_msa.shape[1], \" * \", len(AA_TYPES)+1, \" = \", enumd_msa.shape[1] * (len(AA_TYPES)+1))\n",
    "print(vae.encoder_comm_layers)\n",
    "first_latent = vae.encode(first_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.0034, -0.0266], device='cuda:0', grad_fn=<AddBackward0>), tensor([1.0857, 1.0416], device='cuda:0', grad_fn=<ExpBackward0>))\n"
     ]
    }
   ],
   "source": [
    "print(first_latent)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProtEvoVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
