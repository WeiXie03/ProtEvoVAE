{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ding et. al.'s Paper: Shape through Model\n",
    "\n",
    "In Ding et. al.'s paper, the decoder is parameterized by another fairly straightforward neural net of mostly a series of linear-tanh layers. The only unique part is the last layer, a softmax.\n",
    "\n",
    "Note that line 49 of Ding et. al.'s `train.py` flattens the three-dimensional `seq_msa_binary` numpy array from shape `(# seqs)` x `(alignment len in # a.a.'s)` x `(20 a.a. + 1 for gap)` to a two-dimensional array of one vector for every sequence by just concatenating all the one-hot vectors together: \n",
    "```python\n",
    "seq_msa_binary = seq_msa_binary.reshape((num_seq, -1))\n",
    "```\n",
    "\n",
    "Then in the decoder (in `VAE_model.py`), the activations of the second last layer are reshaped from a flat vector into a two-dimensional array with one vector per amino acid position that represents the probability distribution for each possible a.a. type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 18])  shaped \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alignment_len = 4\n",
    "num_seqs = 2\n",
    "num_types = 6\n",
    "\n",
    "A = np.tile(np.arange(num_types), (alignment_len*num_seqs)//num_types)\n",
    "T_A = F.one_hot(torch.from_numpy(A), num_classes=num_types)\n",
    "T_A = T_A.reshape((num_seqs, -1))\n",
    "\n",
    "# a tuple (# of sequences, )\n",
    "fixed_shape = tuple(T_A.shape[0:-1])\n",
    "\n",
    "print(T_A.shape, \" shaped \")\n",
    "T_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reshape to  (2, -1, 6)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0],\n",
       "         [0, 1, 0, 0, 0, 0],\n",
       "         [0, 0, 1, 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0, 1, 0, 0],\n",
       "         [0, 0, 0, 0, 1, 0],\n",
       "         [0, 0, 0, 0, 0, 1]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"reshape to \", fixed_shape + (-1, num_types))\n",
    "T_A = T_A.view(fixed_shape + (-1, num_types))\n",
    "T_A"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, Ding et. al. do indeed _first_,\n",
    "1. __completely flatten each protein's sequence__ before feeding into the (fully connected) neural network, simply _concatenating together all the one-hot vectors_ for each amino acid position. Then,\n",
    "2. the __decoder__ reshapes the activations of the second last layer into a two-dimensional array with _one vector per amino acid position_ that represents a probability distribution over all 20 a.a. types."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ProtEvoVAE",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
